{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Matching su blockingRulesGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial.distance import euclidean\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo della Distanza \"Intra-Cluster\" Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_distance(elements):\n",
    "    pairs = list(combinations(elements,2))\n",
    "    # Calcola la distanza euclidea tra ciascuna coppia di vettori\n",
    "    distances = [euclidean(pair[0], pair[1]) for pair in pairs]\n",
    "\n",
    "    # Calcola la media delle distanze\n",
    "    mean_distance = np.mean(distances)\n",
    "\n",
    "    #print(\"Media distanza tra i vettori di embedding:\", mean_distance)\n",
    "\n",
    "    return mean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento dello schema mediato con cluster (Rule Based)\n",
    "Osservazione: sia lo Schema Mediato che i BERT Vectors sono permutati con \"random_state=24\", poiché il Blocking sullo Schema Mediato è stato lanciato proprio dopo una sua permutazione con \"random_state=24\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_mediato = pd.read_csv(\"./../datasets/MediatedSchemaSemicolon.csv\",sep=';')\n",
    "schema_mediato = schema_mediato.sample(n=81706, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors = pd.read_csv(\"./../datasets/MediatedSchemaVectors.csv\")\n",
    "bert_vectors = bert_vectors.sample(n=81706, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "with open(\"./../2 - Blocking/blockingRulesGPT/clustering_full_24.txt\") as file:\n",
    "    for line in file:\n",
    "        chiave, valore = line.split(':')\n",
    "        chiave = int(chiave)\n",
    "        valore = int(valore[1:-1])\n",
    "        dictionary[chiave] = valore\n",
    "\n",
    "dictionary_ordinato = dict(sorted(dictionary.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = list(dictionary_ordinato.values())\n",
    "schema_mediato['block'] = block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7504\n"
     ]
    }
   ],
   "source": [
    "num_blocks = schema_mediato['block'].nunique()\n",
    "print(num_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgglomerativeClustering su Vettori estratti dai Record con BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,num_blocks+1):\n",
    "    records_cluster = schema_mediato[schema_mediato['block']==i]\n",
    "    if(len(records_cluster)>1):\n",
    "        vectors_cluster = bert_vectors.loc[records_cluster.index].copy() #lista degli indici di riga per il cluster corrente\n",
    "        distance_threshold = compute_mean_distance(vectors_cluster.values.tolist())\n",
    "        model = AgglomerativeClustering(n_clusters=None,distance_threshold=0.33*distance_threshold).fit(vectors_cluster)\n",
    "        stats[i] = {}\n",
    "        vectors_cluster['cluster'] = model.labels_\n",
    "        for j in range(0,max(model.labels_)):\n",
    "            stats[i][j] = vectors_cluster[vectors_cluster['cluster']==j].index.tolist()\n",
    "    else:\n",
    "        stats[i] = {}\n",
    "        stats[i][0] = records_cluster.index.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvataggio su File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results_clustersChatGPT.txt\", \"w\") as file:\n",
    "    # Iterare sul dizionario e scrivere ogni coppia chiave-valore su una nuova riga\n",
    "    for chiave, valore in stats.items():\n",
    "        file.write(f\"{chiave}: {valore}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalProjectIDD3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
